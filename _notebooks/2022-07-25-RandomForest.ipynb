{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84e383aa-91d4-4efa-92e9-9671303e7b66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RandomForest\n",
    "> \"작성완료\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: 최민아\n",
    "- categories: [python]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f3e46-66ff-4654-9173-86e8e1259d33",
   "metadata": {},
   "source": [
    "`-` (1/3): 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a804d5a-aef0-469a-b819-98760e99d749",
   "metadata": {},
   "source": [
    "`-` (2/3): 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732438f3-e2a3-4a3a-b922-4ca6641c1301",
   "metadata": {},
   "source": [
    "`-` (3/3): 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6593f4-3982-4901-bde2-fff546c732c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **전처리**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab118af5-20ce-40c3-8c84-ec009b39465d",
   "metadata": {},
   "source": [
    "#### 결측치 평균으로 대체\n",
    "df.fillna({'열 이름':int(df['열 이름'].mean)}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a09e10d-0026-4a60-8343-090c800f7a29",
   "metadata": {},
   "source": [
    "#### 결측치 보간법으로 대체\n",
    "결측치를 이전 행과 다음 행의 평균으로 보간\n",
    "\n",
    "df.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359bcb2-578e-4ce4-9d5e-89cbd14ac21c",
   "metadata": {},
   "source": [
    "### **모델링**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91659416-3df3-4636-ae8b-6bd8fb5a939e",
   "metadata": {},
   "source": [
    "#### 랜덤포레스트\n",
    "랜덤포레스트 : 여러 개의 의사결정나무를 만들어 이들의 평균으로 예측 성능을 높이는 방법 (앙상블 기법)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8905e-611e-4c75-b63e-3e6793555962",
   "metadata": {},
   "source": [
    "#### 랜덤포레스트 평가척도 학습\n",
    "criterion 옵션으로 어떤 평가척도를 기준으로 훈련할 것인지 지정\n",
    "\n",
    "RMSE : sqrt(MSE 평가지표)\n",
    "\n",
    "model = RandomForestRegressor(criterion = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c1335-8290-4990-981c-0da009e8fc35",
   "metadata": {},
   "source": [
    "### **튜닝**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa667bfd-3a75-4dbe-a431-1ae73e0dc782",
   "metadata": {},
   "source": [
    "#### 변수중요도\n",
    "변수의 중요도 : 예측변수를 결정할 때 각 피쳐가 얼마나 중요한 역할을 하는지에 대한 척도\n",
    "\n",
    "변수의 중요도가 낮다면 해당 피쳐를 제거하는 것이 모델의 성능을 높일 수 있다.\n",
    "\n",
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50953c8a-662e-44f0-aa7d-c24c1f71456a",
   "metadata": {},
   "source": [
    "#### 변수 제거\n",
    "`-` 변수 중요도가 낮은 피쳐를 파악하고 차례대로 하나씩 피쳐를 제거하며 모델을 훈련\n",
    "\n",
    "`-` train 세트에서 제거한 피쳐는 test 세트에서 동일하게 drop 후 모델 훈련\n",
    "\n",
    "`-` drop\n",
    "X_train_1 = train.drop(['drop 할 피쳐'], axis=1)\n",
    "\n",
    "test_1 = test.drop(['drop 할 피쳐'], axis = 1)\n",
    "\n",
    "`-` 모델 훈련\n",
    "\n",
    "model_input_var1 = RandomForestRegressor(criterion = 'mse')\n",
    "\n",
    "model_input_var1.fit(X_train_1, Y_train)\n",
    "\n",
    "`-` test 세트 예측\n",
    "\n",
    "y_pred_1 = model_input_var1.predict(test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d4c85-f505-4bfd-8d1a-0f39d12736e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 하이퍼파라미터\n",
    "하이퍼 파라미터 : 정지규칙 값 설정\n",
    "\n",
    "`-` (1/4) 최대 깊이 (max_depth) : 뿌리 노드로부터 내려갈 수 있는 깊이 지정 (작을수록 트리는 작아짐)\n",
    "\n",
    "`-` (2/4) 최소 노드크기 (min_samples_split) : 노드를 분할하기 위한 데이터 수, 해당 노드에 이 값보다 적은 확률변수가 있다면 stop. (작을수록 트리는 커짐)\n",
    "\n",
    "`-` (3/4) 최소 향상도 (min_impurity_decrease) : 향상도가 설정값 이하라면 더이상 분할하지 않음. (작을수록 트리는 커짐)\n",
    "\n",
    "`-` (4/4) 비용복잡도 (Cost-complexity) : 트리가 커지는 것에 대해 패널티 계수를 정하여 불순도와 트리가 커지는 것에 대해 복잡도를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4310d009-679f-4c6c-804f-3dacd8b2f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee36f1f-6c06-4496-9d5e-fcfa788bce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "treeterms = 'https://gmlwjd9405.github.io/images/data-structure-tree/tree-terms.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb9d9e8a-4eb3-437d-aa0b-5399d86f4ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src= 'https://gmlwjd9405.github.io/images/data-structure-tree/tree-terms.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "htmlstr = \"<img src= '{url}'>\"\n",
    "display(HTML(htmlstr.format(url=treeterms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a60dffb-4625-4f95-bab8-0f914226034b",
   "metadata": {},
   "source": [
    "- 루트 노드(root node): 부모가 없는 노드, 트리는 하나의 루트 노드만을 가진다.\n",
    "- 단말 노드(leaf node): 자식이 없는 노드, ‘말단 노드’ 또는 ‘잎 노드’라고도 부른다.\n",
    "- 내부(internal) 노드: 단말 노드가 아닌 노드\n",
    "- 간선(edge): 노드를 연결하는 선 (link, branch 라고도 부름)\n",
    "- 형제(sibling): 같은 부모를 가지는 노드\n",
    "- 노드의 크기(size): 자신을 포함한 모든 자손 노드의 개수\n",
    "- 노드의 깊이(depth): 루트에서 어떤 노드에 도달하기 위해 거쳐야 하는 간선의 수\n",
    "- 노드의 레벨(level): 트리의 특정 깊이를 가지는 노드의 집합\n",
    "- 노드의 차수(degree): 하위 트리 개수 / 간선 수 (degree) = 각 노드가 지닌 가지의 수\n",
    "- 트리의 차수(degree of tree): 트리의 최대 차수\n",
    "- 트리의 높이(height): 루트 노드에서 가장 깊숙히 있는 노드의 깊이\n",
    "\n",
    "출처 : https://gmlwjd9405.github.io/2018/08/12/data-structure-tree.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c546a85-f726-4863-aafb-9f98e14abb38",
   "metadata": {},
   "source": [
    "#### GridSearch \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(criterion = 'mse', random_state=2020)\n",
    "\n",
    "\n",
    "params = {'n_estimators': [200, 300, 500],\n",
    "    \n",
    "          'max_features': [5, 6, 8],\n",
    "          \n",
    "          'min_samples_leaf': [1, 3, 5]}\n",
    "\n",
    "\n",
    "greedy_CV = GridSearchCV(model, param_grid=params, cv = 3, n_jobs = -1)\n",
    "\n",
    "greedy_CV.fit(X_train, Y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
