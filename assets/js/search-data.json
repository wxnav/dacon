{
  
    
        "post0": {
            "title": "Seoul Public Bike rental prediction with DecisionTreeClassifier",
            "content": "EDA . import . import pandas as pd import numpy as np import sklearn from sklearn.tree import DecisionTreeClassifier . train = pd.read_csv(&quot;seoulbikedata/train.csv&quot;) test = pd.read_csv(&quot;seoulbikedata/test.csv&quot;) . row column . train.shape . (1459, 11) . test.shape . (715, 10) . checking data . train.head() . id hour hour_bef_temperature hour_bef_precipitation hour_bef_windspeed hour_bef_humidity hour_bef_visibility hour_bef_ozone hour_bef_pm10 hour_bef_pm2.5 count . 0 3 | 20 | 16.3 | 1.0 | 1.5 | 89.0 | 576.0 | 0.027 | 76.0 | 33.0 | 49.0 | . 1 6 | 13 | 20.1 | 0.0 | 1.4 | 48.0 | 916.0 | 0.042 | 73.0 | 40.0 | 159.0 | . 2 7 | 6 | 13.9 | 0.0 | 0.7 | 79.0 | 1382.0 | 0.033 | 32.0 | 19.0 | 26.0 | . 3 8 | 23 | 8.1 | 0.0 | 2.7 | 54.0 | 946.0 | 0.040 | 75.0 | 64.0 | 57.0 | . 4 9 | 18 | 29.5 | 0.0 | 4.8 | 7.0 | 2000.0 | 0.057 | 27.0 | 11.0 | 431.0 | . train.tail() . id hour hour_bef_temperature hour_bef_precipitation hour_bef_windspeed hour_bef_humidity hour_bef_visibility hour_bef_ozone hour_bef_pm10 hour_bef_pm2.5 count . 1454 2174 | 4 | 16.8 | 0.0 | 1.6 | 53.0 | 2000.0 | 0.031 | 37.0 | 27.0 | 21.0 | . 1455 2175 | 3 | 10.8 | 0.0 | 3.8 | 45.0 | 2000.0 | 0.039 | 34.0 | 19.0 | 20.0 | . 1456 2176 | 5 | 18.3 | 0.0 | 1.9 | 54.0 | 2000.0 | 0.009 | 30.0 | 21.0 | 22.0 | . 1457 2178 | 21 | 20.7 | 0.0 | 3.7 | 37.0 | 1395.0 | 0.082 | 71.0 | 36.0 | 216.0 | . 1458 2179 | 17 | 21.1 | 0.0 | 3.1 | 47.0 | 1973.0 | 0.046 | 38.0 | 17.0 | 170.0 | . test.head() . id hour hour_bef_temperature hour_bef_precipitation hour_bef_windspeed hour_bef_humidity hour_bef_visibility hour_bef_ozone hour_bef_pm10 hour_bef_pm2.5 . 0 0 | 7 | 20.7 | 0.0 | 1.3 | 62.0 | 954.0 | 0.041 | 44.0 | 27.0 | . 1 1 | 17 | 30.0 | 0.0 | 5.4 | 33.0 | 1590.0 | 0.061 | 49.0 | 36.0 | . 2 2 | 13 | 19.0 | 1.0 | 2.1 | 95.0 | 193.0 | 0.020 | 36.0 | 28.0 | . 3 4 | 6 | 22.5 | 0.0 | 2.5 | 60.0 | 1185.0 | 0.027 | 52.0 | 38.0 | . 4 5 | 22 | 14.6 | 1.0 | 3.4 | 93.0 | 218.0 | 0.041 | 18.0 | 15.0 | . test.tail() . id hour hour_bef_temperature hour_bef_precipitation hour_bef_windspeed hour_bef_humidity hour_bef_visibility hour_bef_ozone hour_bef_pm10 hour_bef_pm2.5 . 710 2148 | 1 | 24.6 | 0.0 | 2.4 | 60.0 | 1745.0 | NaN | NaN | NaN | . 711 2149 | 1 | 18.1 | 0.0 | 1.0 | 55.0 | 2000.0 | NaN | NaN | NaN | . 712 2165 | 9 | 23.3 | 0.0 | 2.3 | 66.0 | 1789.0 | 0.020 | 17.0 | 15.0 | . 713 2166 | 16 | 27.0 | 0.0 | 1.6 | 46.0 | 1956.0 | 0.032 | 40.0 | 26.0 | . 714 2177 | 8 | 22.3 | 0.0 | 1.0 | 63.0 | 1277.0 | 0.007 | 30.0 | 24.0 | . checking missing value . train.isnull().sum() . id 0 hour 0 hour_bef_temperature 2 hour_bef_precipitation 2 hour_bef_windspeed 9 hour_bef_humidity 2 hour_bef_visibility 2 hour_bef_ozone 76 hour_bef_pm10 90 hour_bef_pm2.5 117 count 0 dtype: int64 . test.isnull().sum() . id 0 hour 0 hour_bef_temperature 1 hour_bef_precipitation 1 hour_bef_windspeed 1 hour_bef_humidity 1 hour_bef_visibility 1 hour_bef_ozone 35 hour_bef_pm10 37 hour_bef_pm2.5 36 dtype: int64 . pretreatment . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1459 entries, 0 to 1458 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 id 1459 non-null int64 1 hour 1459 non-null int64 2 hour_bef_temperature 1457 non-null float64 3 hour_bef_precipitation 1457 non-null float64 4 hour_bef_windspeed 1450 non-null float64 5 hour_bef_humidity 1457 non-null float64 6 hour_bef_visibility 1457 non-null float64 7 hour_bef_ozone 1383 non-null float64 8 hour_bef_pm10 1369 non-null float64 9 hour_bef_pm2.5 1342 non-null float64 10 count 1459 non-null float64 dtypes: float64(9), int64(2) memory usage: 125.5 KB . test.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 715 entries, 0 to 714 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 id 715 non-null int64 1 hour 715 non-null int64 2 hour_bef_temperature 714 non-null float64 3 hour_bef_precipitation 714 non-null float64 4 hour_bef_windspeed 714 non-null float64 5 hour_bef_humidity 714 non-null float64 6 hour_bef_visibility 714 non-null float64 7 hour_bef_ozone 680 non-null float64 8 hour_bef_pm10 678 non-null float64 9 hour_bef_pm2.5 679 non-null float64 dtypes: float64(8), int64(2) memory usage: 56.0 KB . train[train.notnull()].mean() . id 1105.914325 hour 11.493489 hour_bef_temperature 16.717433 hour_bef_precipitation 0.031572 hour_bef_windspeed 2.479034 hour_bef_humidity 52.231297 hour_bef_visibility 1405.216884 hour_bef_ozone 0.039149 hour_bef_pm10 57.168736 hour_bef_pm2.5 30.327124 count 108.563400 dtype: float64 . test[test.notnull()].mean() . id 1056.854545 hour 11.472727 hour_bef_temperature 23.263305 hour_bef_precipitation 0.051821 hour_bef_windspeed 2.388515 hour_bef_humidity 56.668067 hour_bef_visibility 1359.494398 hour_bef_ozone 0.041196 hour_bef_pm10 36.930678 hour_bef_pm2.5 24.939617 dtype: float64 . train.fillna(train.mean()) . id hour hour_bef_temperature hour_bef_precipitation hour_bef_windspeed hour_bef_humidity hour_bef_visibility hour_bef_ozone hour_bef_pm10 hour_bef_pm2.5 count . 0 3 | 20 | 16.3 | 1.0 | 1.5 | 89.0 | 576.0 | 0.027 | 76.0 | 33.0 | 49.0 | . 1 6 | 13 | 20.1 | 0.0 | 1.4 | 48.0 | 916.0 | 0.042 | 73.0 | 40.0 | 159.0 | . 2 7 | 6 | 13.9 | 0.0 | 0.7 | 79.0 | 1382.0 | 0.033 | 32.0 | 19.0 | 26.0 | . 3 8 | 23 | 8.1 | 0.0 | 2.7 | 54.0 | 946.0 | 0.040 | 75.0 | 64.0 | 57.0 | . 4 9 | 18 | 29.5 | 0.0 | 4.8 | 7.0 | 2000.0 | 0.057 | 27.0 | 11.0 | 431.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1454 2174 | 4 | 16.8 | 0.0 | 1.6 | 53.0 | 2000.0 | 0.031 | 37.0 | 27.0 | 21.0 | . 1455 2175 | 3 | 10.8 | 0.0 | 3.8 | 45.0 | 2000.0 | 0.039 | 34.0 | 19.0 | 20.0 | . 1456 2176 | 5 | 18.3 | 0.0 | 1.9 | 54.0 | 2000.0 | 0.009 | 30.0 | 21.0 | 22.0 | . 1457 2178 | 21 | 20.7 | 0.0 | 3.7 | 37.0 | 1395.0 | 0.082 | 71.0 | 36.0 | 216.0 | . 1458 2179 | 17 | 21.1 | 0.0 | 3.1 | 47.0 | 1973.0 | 0.046 | 38.0 | 17.0 | 170.0 | . 1459 rows × 11 columns . test.fillna(test.mean()) . id hour hour_bef_temperature hour_bef_precipitation hour_bef_windspeed hour_bef_humidity hour_bef_visibility hour_bef_ozone hour_bef_pm10 hour_bef_pm2.5 . 0 0 | 7 | 20.7 | 0.0 | 1.3 | 62.0 | 954.0 | 0.041000 | 44.000000 | 27.000000 | . 1 1 | 17 | 30.0 | 0.0 | 5.4 | 33.0 | 1590.0 | 0.061000 | 49.000000 | 36.000000 | . 2 2 | 13 | 19.0 | 1.0 | 2.1 | 95.0 | 193.0 | 0.020000 | 36.000000 | 28.000000 | . 3 4 | 6 | 22.5 | 0.0 | 2.5 | 60.0 | 1185.0 | 0.027000 | 52.000000 | 38.000000 | . 4 5 | 22 | 14.6 | 1.0 | 3.4 | 93.0 | 218.0 | 0.041000 | 18.000000 | 15.000000 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 710 2148 | 1 | 24.6 | 0.0 | 2.4 | 60.0 | 1745.0 | 0.041196 | 36.930678 | 24.939617 | . 711 2149 | 1 | 18.1 | 0.0 | 1.0 | 55.0 | 2000.0 | 0.041196 | 36.930678 | 24.939617 | . 712 2165 | 9 | 23.3 | 0.0 | 2.3 | 66.0 | 1789.0 | 0.020000 | 17.000000 | 15.000000 | . 713 2166 | 16 | 27.0 | 0.0 | 1.6 | 46.0 | 1956.0 | 0.032000 | 40.000000 | 26.000000 | . 714 2177 | 8 | 22.3 | 0.0 | 1.0 | 63.0 | 1277.0 | 0.007000 | 30.000000 | 24.000000 | . 715 rows × 10 columns . modeling . X_train = train.drop([&#39;count&#39;], axis=1) Y_train = train[&#39;count&#39;] . model = DecisionTreeClassifier() . model.fit(X_train, Y_train) . ValueError Traceback (most recent call last) Input In [23], in &lt;module&gt; -&gt; 1 model.fit(X_train, Y_train) File D: anaconda3 envs ip2022 lib site-packages sklearn tree _classes.py:937, in DecisionTreeClassifier.fit(self, X, y, sample_weight, check_input, X_idx_sorted) 899 def fit( 900 self, X, y, sample_weight=None, check_input=True, X_idx_sorted=&#34;deprecated&#34; 901 ): 902 &#34;&#34;&#34;Build a decision tree classifier from the training set (X, y). 903 904 Parameters (...) 934 Fitted estimator. 935 &#34;&#34;&#34; --&gt; 937 super().fit( 938 X, 939 y, 940 sample_weight=sample_weight, 941 check_input=check_input, 942 X_idx_sorted=X_idx_sorted, 943 ) 944 return self File D: anaconda3 envs ip2022 lib site-packages sklearn tree _classes.py:165, in BaseDecisionTree.fit(self, X, y, sample_weight, check_input, X_idx_sorted) 163 check_X_params = dict(dtype=DTYPE, accept_sparse=&#34;csc&#34;) 164 check_y_params = dict(ensure_2d=False, dtype=None) --&gt; 165 X, y = self._validate_data( 166 X, y, validate_separately=(check_X_params, check_y_params) 167 ) 168 if issparse(X): 169 X.sort_indices() File D: anaconda3 envs ip2022 lib site-packages sklearn base.py:578, in BaseEstimator._validate_data(self, X, y, reset, validate_separately, **check_params) 572 if validate_separately: 573 # We need this because some estimators validate X and y 574 # separately, and in general, separately calling check_array() 575 # on X and y isn&#39;t equivalent to just calling check_X_y() 576 # :( 577 check_X_params, check_y_params = validate_separately --&gt; 578 X = check_array(X, **check_X_params) 579 y = check_array(y, **check_y_params) 580 else: File D: anaconda3 envs ip2022 lib site-packages sklearn utils validation.py:800, in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator) 794 raise ValueError( 795 &#34;Found array with dim %d. %s expected &lt;= 2.&#34; 796 % (array.ndim, estimator_name) 797 ) 799 if force_all_finite: --&gt; 800 _assert_all_finite(array, allow_nan=force_all_finite == &#34;allow-nan&#34;) 802 if ensure_min_samples &gt; 0: 803 n_samples = _num_samples(array) File D: anaconda3 envs ip2022 lib site-packages sklearn utils validation.py:114, in _assert_all_finite(X, allow_nan, msg_dtype) 107 if ( 108 allow_nan 109 and np.isinf(X).any() 110 or not allow_nan 111 and not np.isfinite(X).all() 112 ): 113 type_err = &#34;infinity&#34; if allow_nan else &#34;NaN, infinity&#34; --&gt; 114 raise ValueError( 115 msg_err.format( 116 type_err, msg_dtype if msg_dtype is not None else X.dtype 117 ) 118 ) 119 # for object dtype data, we only check for NaNs (GH-13254) 120 elif X.dtype == np.dtype(&#34;object&#34;) and not allow_nan: ValueError: Input contains NaN, infinity or a value too large for dtype(&#39;float32&#39;). . ? .",
            "url": "https://wxnav.github.io/dacon/python/2022/07/22/%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%ED%9A%8C%EA%B7%80%EB%82%98%EB%AC%B4%EB%94%B0%EB%A6%89%EC%9D%B4.html",
            "relUrl": "/python/2022/07/22/%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%ED%9A%8C%EA%B7%80%EB%82%98%EB%AC%B4%EB%94%B0%EB%A6%89%EC%9D%B4.html",
            "date": " • Jul 22, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "DecisionTreeClassifier",
            "content": "- (1/3): EDA(Exploratory Data Analysis) . - (2/3): 전처리 . - (3/3): 모델링 . EDA(Exploratory Data Analysis) . - &#46972;&#51060;&#48652;&#47084;&#47532; &#48520;&#47084;&#50724;&#44592; . import &quot;라이브러리&quot; as &quot;사용할 이름&quot; . - &#54028;&#51068; &#48520;&#47084;&#50724;&#44592; . import pandas as pd . data = pd.read_csv(&quot;파일 경로/ 파일 이름.csv&quot;) . - &#54665;, &#50676; &#44060;&#49688; &#44288;&#52272;&#54616;&#44592; . df.shape . - &#45936;&#51060;&#53552; &#54869;&#51064;&#54616;&#44592; . import pandas as pd . df = pd.read_csv(&#39;data/df.csv&#39;) . df.head() #상단 5개 행 출력 . df.tail() #하단 5개 행 출력 . - &#44208;&#52769;&#52824; &#54869;&#51064;&#54616;&#44592; . df.isnull() : 데이터가 NaN인 경우 True . df.isnull().sum() : 데이터프레임의 각 열 별 결측치의 수 . &#51204;&#52376;&#47532; . - &#45936;&#51060;&#53552; &#44592;&#48376; &#51221;&#48372; &#54869;&#51064; . df.info() : 피쳐들의 기본 정보(결측치, 데이터 타입 등) 확인 . - &#44208;&#52769;&#52824; &#49325;&#51228;, &#45824;&#52404; . df.dropna() : 결측치 삭제 . df.fillna() : 결측치 인자값 대체 . &#47784;&#45944;&#47553; . - scikit-learn . import sklearn from sklearn.tree import DecisionTreeClassifier . - &#51032;&#49324;&#44208;&#51221;&#45208;&#47924; &#47784;&#45944; . 노드 : 훈련 데이터의 특성에 대한 테스트 표현 . 이진분할 : 하나의 피쳐를 정해 해당 피쳐의 값에 대해 특정한 하나의 값을 정한다면, 이를 기준으로 모든 행을 두 개의 노드로 분류 (특정한 두 개의 값을 정한다면 삼진분할) . 원리 : 파생된 두 개의 노드에 대해서 또 다시 새로운 피쳐의 특정한 값을 정하고 분류를 진행하고, 이 과정을 반복하게 되면 점차 피쳐의 값에 따라 data 들이 분류 . import sklearn from sklearn.tree import DecisionTreeClassifier . - &#47784;&#45944; &#54984;&#47144; . X : 예측 변수 . Y : 반응 변수 . X_train = train.drop([&#39;제외할 열&#39;], axis=1) . Y_train = train[&#39;예측할 열&#39;] . model = DecistionRegressor() . model.fit(X_train, Y_train) . - &#53580;&#49828;&#53944; &#50696;&#52769; . 할당할 array = model.predict(data) . - &#48373;&#49845; . 라이브러리 불러오기 import | 데이터 불러오기 read_csv() | 데이터 정보 관찰하기 head() | 데이터 행열 개수 관찰 shape | 결측치 확인 info() | 결측치 전처리 dropna(), fillna() | 모델 훈련 fit() | 테스트 파일 예측 predict() | submission 파일 생성 to_csv() | .",
            "url": "https://wxnav.github.io/dacon/jupyter/2022/07/21/DecisionTreeClassifier.html",
            "relUrl": "/jupyter/2022/07/21/DecisionTreeClassifier.html",
            "date": " • Jul 21, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://wxnav.github.io/dacon/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://wxnav.github.io/dacon/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "수상 . - [2019] . 프로젝트 . - [2019] . - 산림공공·빅데이터 활용 창업경진대회 [2022.05.17 - 2022.07.10] . 프로그래밍 스킬 . - Python . - R . - C Programming language .",
          "url": "https://wxnav.github.io/dacon/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://wxnav.github.io/dacon/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}